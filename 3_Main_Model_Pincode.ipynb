{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac284ecf",
   "metadata": {},
   "source": [
    "#  Walmart Return Optimization project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c5e92",
   "metadata": {},
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e47c303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (1.7.0)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (4.6.0)\n",
      "Requirement already satisfied: groq in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (0.28.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from groq) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aryan\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy scikit-learn lightgbm groq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f5033d",
   "metadata": {},
   "source": [
    " Import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bff2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc436fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Synthetic CSV saved.\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic dataset with random lat/lon\n",
    "n = 2000\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    \"sku_id\": [f\"PRD-{i}\" for i in range(n)],\n",
    "    \"category\": np.random.choice([\"Electronics\", \"Beauty\", \"Kitchen\", \"Apparel\"], n),\n",
    "    \"original_price\": np.random.randint(500, 30000, n),\n",
    "    \"condition_grade\": np.random.choice([\"A\", \"B\", \"C\", \"D\"], n),\n",
    "    \"return_reason_code\": np.random.choice([\"01\", \"02\", \"03\", \"04\"], n),\n",
    "    \"estimated_refurb_cost\": np.random.randint(50, 5000, n),\n",
    "    \"resale_value_estimated\": np.random.randint(100, 25000, n),\n",
    "    \"inbound_shipping_cost\": np.random.randint(20, 500, n),\n",
    "    \"hazardous_goods_flag\": np.random.choice([\"Yes\", \"No\"], n),\n",
    "    \"co2_saved_refurb_vs_landfill\": np.random.uniform(0.1, 5.0, n),\n",
    "    \"final_decision\": np.random.choice(\n",
    "        [\"refurbish\", \"liquidate\", \"recycle\", \"keep_it\", \"donate\"],\n",
    "        n\n",
    "    ),\n",
    "    \"customer_latitude\": np.random.uniform(8, 37, n),\n",
    "    \"customer_longitude\": np.random.uniform(68, 97, n)\n",
    "})\n",
    "\n",
    "data.to_csv(\"synthetic_returns_data.csv\", index=False)\n",
    "print(\" Synthetic CSV saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a75edf",
   "metadata": {},
   "source": [
    "#  Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "269da599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV you just generated\n",
    "df = pd.read_csv(\"synthetic_returns_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326aeed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_id</th>\n",
       "      <th>category</th>\n",
       "      <th>original_price</th>\n",
       "      <th>condition_grade</th>\n",
       "      <th>return_reason_code</th>\n",
       "      <th>estimated_refurb_cost</th>\n",
       "      <th>resale_value_estimated</th>\n",
       "      <th>inbound_shipping_cost</th>\n",
       "      <th>hazardous_goods_flag</th>\n",
       "      <th>co2_saved_refurb_vs_landfill</th>\n",
       "      <th>final_decision</th>\n",
       "      <th>customer_latitude</th>\n",
       "      <th>customer_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRD-0</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>17577</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1151</td>\n",
       "      <td>13588</td>\n",
       "      <td>320</td>\n",
       "      <td>No</td>\n",
       "      <td>4.136504</td>\n",
       "      <td>liquidate</td>\n",
       "      <td>36.175973</td>\n",
       "      <td>78.111838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRD-1</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>2481</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>4053</td>\n",
       "      <td>4363</td>\n",
       "      <td>53</td>\n",
       "      <td>No</td>\n",
       "      <td>1.336327</td>\n",
       "      <td>recycle</td>\n",
       "      <td>26.779193</td>\n",
       "      <td>82.134553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRD-2</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>5870</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>4323</td>\n",
       "      <td>7375</td>\n",
       "      <td>296</td>\n",
       "      <td>No</td>\n",
       "      <td>0.505316</td>\n",
       "      <td>donate</td>\n",
       "      <td>26.272797</td>\n",
       "      <td>92.056468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRD-3</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>5080</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>3200</td>\n",
       "      <td>8009</td>\n",
       "      <td>314</td>\n",
       "      <td>No</td>\n",
       "      <td>3.611764</td>\n",
       "      <td>refurbish</td>\n",
       "      <td>19.113215</td>\n",
       "      <td>81.718231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRD-4</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>8165</td>\n",
       "      <td>D</td>\n",
       "      <td>3</td>\n",
       "      <td>161</td>\n",
       "      <td>13903</td>\n",
       "      <td>182</td>\n",
       "      <td>No</td>\n",
       "      <td>0.193871</td>\n",
       "      <td>donate</td>\n",
       "      <td>27.430086</td>\n",
       "      <td>70.043635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sku_id     category  original_price condition_grade  return_reason_code  \\\n",
       "0  PRD-0      Apparel           17577               A                   1   \n",
       "1  PRD-1      Kitchen            2481               C                   4   \n",
       "2  PRD-2      Apparel            5870               B                   1   \n",
       "3  PRD-3  Electronics            5080               C                   3   \n",
       "4  PRD-4  Electronics            8165               D                   3   \n",
       "\n",
       "   estimated_refurb_cost  resale_value_estimated  inbound_shipping_cost  \\\n",
       "0                   1151                   13588                    320   \n",
       "1                   4053                    4363                     53   \n",
       "2                   4323                    7375                    296   \n",
       "3                   3200                    8009                    314   \n",
       "4                    161                   13903                    182   \n",
       "\n",
       "  hazardous_goods_flag  co2_saved_refurb_vs_landfill final_decision  \\\n",
       "0                   No                      4.136504      liquidate   \n",
       "1                   No                      1.336327        recycle   \n",
       "2                   No                      0.505316         donate   \n",
       "3                   No                      3.611764      refurbish   \n",
       "4                   No                      0.193871         donate   \n",
       "\n",
       "   customer_latitude  customer_longitude  \n",
       "0          36.175973           78.111838  \n",
       "1          26.779193           82.134553  \n",
       "2          26.272797           92.056468  \n",
       "3          19.113215           81.718231  \n",
       "4          27.430086           70.043635  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da9c6c",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215537b",
   "metadata": {},
   "source": [
    "# Encode Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10c64db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca2ef9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_cols = [\"category\", \"condition_grade\", \n",
    "                    \"return_reason_code\", \"hazardous_goods_flag\", \"final_decision\"]\n",
    "\n",
    "le_dict = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    le_dict[col] = le\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcfe765",
   "metadata": {},
   "source": [
    "# loading of location info csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a32c7637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157126, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_28364\\4035986862.py:1: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  post_df = pd.read_csv(\"pincode_with_lat-long.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OfficeName</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>StateName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peddakotla B.O</td>\n",
       "      <td>14.5689</td>\n",
       "      <td>77.85624</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pinnadhari B.O</td>\n",
       "      <td>14.5281</td>\n",
       "      <td>77.857014</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yerraguntapalle B.O</td>\n",
       "      <td>14.561111</td>\n",
       "      <td>77.85715</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Obulareddipalli B.O</td>\n",
       "      <td>14.2488</td>\n",
       "      <td>78.2588</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Odulapalli B.O</td>\n",
       "      <td>14.24555</td>\n",
       "      <td>78.2477</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OfficeName   Latitude  Longitude       StateName\n",
       "0       Peddakotla B.O    14.5689   77.85624  ANDHRA PRADESH\n",
       "1       Pinnadhari B.O    14.5281  77.857014  ANDHRA PRADESH\n",
       "2  Yerraguntapalle B.O  14.561111   77.85715  ANDHRA PRADESH\n",
       "3  Obulareddipalli B.O    14.2488    78.2588  ANDHRA PRADESH\n",
       "4       Odulapalli B.O   14.24555    78.2477  ANDHRA PRADESH"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df = pd.read_csv(\"pincode_with_lat-long.csv\")\n",
    "\n",
    "# Keep only essential columns\n",
    "\n",
    "post_df = post_df[[\"OfficeName\", \"Latitude\", \"Longitude\", \"StateName\"]]\n",
    "\n",
    "print(post_df.shape)\n",
    "\n",
    "post_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "747a96f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OfficeName</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>StateName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157121</th>\n",
       "      <td>Rly Road Meerut SO</td>\n",
       "      <td>28.98</td>\n",
       "      <td>77.68</td>\n",
       "      <td>UTTAR PRADESH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157122</th>\n",
       "      <td>SGMandi SO</td>\n",
       "      <td>28.9724</td>\n",
       "      <td>77.67536</td>\n",
       "      <td>UTTAR PRADESH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157123</th>\n",
       "      <td>W K Road SO</td>\n",
       "      <td>28.99</td>\n",
       "      <td>77.71</td>\n",
       "      <td>UTTAR PRADESH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157124</th>\n",
       "      <td>Kakkoti SO</td>\n",
       "      <td>11.24529</td>\n",
       "      <td>75.778455</td>\n",
       "      <td>KERALA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157125</th>\n",
       "      <td>Kotuvalli SO</td>\n",
       "      <td>11.35</td>\n",
       "      <td>75.91</td>\n",
       "      <td>KERALA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                OfficeName  Latitude  Longitude      StateName\n",
       "157121  Rly Road Meerut SO     28.98      77.68  UTTAR PRADESH\n",
       "157122          SGMandi SO   28.9724   77.67536  UTTAR PRADESH\n",
       "157123         W K Road SO     28.99      77.71  UTTAR PRADESH\n",
       "157124          Kakkoti SO  11.24529  75.778455         KERALA\n",
       "157125        Kotuvalli SO     11.35      75.91         KERALA"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "813150e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OfficeName       0\n",
       "Latitude      8838\n",
       "Longitude     8843\n",
       "StateName        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036e4c3",
   "metadata": {},
   "source": [
    "# Drop rows where lat/lon missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d8cdace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned hubs shape: (148279, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OfficeName</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>StateName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peddakotla B.O</td>\n",
       "      <td>14.5689</td>\n",
       "      <td>77.85624</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pinnadhari B.O</td>\n",
       "      <td>14.5281</td>\n",
       "      <td>77.857014</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yerraguntapalle B.O</td>\n",
       "      <td>14.561111</td>\n",
       "      <td>77.85715</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Obulareddipalli B.O</td>\n",
       "      <td>14.2488</td>\n",
       "      <td>78.2588</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Odulapalli B.O</td>\n",
       "      <td>14.24555</td>\n",
       "      <td>78.2477</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OfficeName   Latitude  Longitude       StateName\n",
       "0       Peddakotla B.O    14.5689   77.85624  ANDHRA PRADESH\n",
       "1       Pinnadhari B.O    14.5281  77.857014  ANDHRA PRADESH\n",
       "2  Yerraguntapalle B.O  14.561111   77.85715  ANDHRA PRADESH\n",
       "3  Obulareddipalli B.O    14.2488    78.2588  ANDHRA PRADESH\n",
       "4       Odulapalli B.O   14.24555    78.2477  ANDHRA PRADESH"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "post_df = post_df.dropna(subset=[\"Latitude\", \"Longitude\"])\n",
    "\n",
    "print(\"Cleaned hubs shape:\", post_df.shape)\n",
    "post_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c902e81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OfficeName    0\n",
       "Latitude      0\n",
       "Longitude     0\n",
       "StateName     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49827bb7",
   "metadata": {},
   "source": [
    "# Compute real-world distance (km) between customer and hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e418e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Calculate haversine distance in kilometers\n",
    "# def haversine(lat1, lon1, lat2, lon2):\n",
    "#     R = 6371\n",
    "#     lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "#     dlat = lat2 - lat1\n",
    "#     dlon = lon2 - lon1\n",
    "#     a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "#     c = 2 * np.arcsin(np.sqrt(a))\n",
    "#     return R * c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d286fa59",
   "metadata": {},
   "source": [
    "# Compute Nearest Hub Distance----Compute distance from each customer to the nearest hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b243a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46a8169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances = []\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     if pd.notnull(row[\"customer_latitude\"]) and pd.notnull(row[\"customer_longitude\"]):\n",
    "\n",
    "#         lat = float(row[\"customer_latitude\"])\n",
    "#         lon = float(row[\"customer_longitude\"])\n",
    "        \n",
    "#         post_df[\"dist\"] = post_df.apply(\n",
    "#             lambda hub: haversine(\n",
    "#                 lat, lon,\n",
    "#                 hub[\"Latitude\"], hub[\"Longitude\"]\n",
    "#             ),\n",
    "#             axis=1\n",
    "#         )\n",
    "        \n",
    "#         min_distance = post_df[\"dist\"].min()\n",
    "#     else:\n",
    "#         min_distance = np.nan\n",
    "\n",
    "#     distances.append(min_distance)\n",
    "\n",
    "# df[\"distance_to_nearest_hub\"] = distances\n",
    "# print(\"✅ Added distance feature.\")\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2859e8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '31.4398200-'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     25\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(val), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# 2. Apply cleaning to post_df\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m \n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Create clean numeric lat/lon and store direction letters\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m post_df[\u001b[33m\"\u001b[39m\u001b[33mLatitude_clean\u001b[39m\u001b[33m\"\u001b[39m], post_df[\u001b[33m\"\u001b[39m\u001b[33mLatitude_dir\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mzip\u001b[39m(*\u001b[43mpost_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLatitude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_latlon\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     36\u001b[39m post_df[\u001b[33m\"\u001b[39m\u001b[33mLongitude_clean\u001b[39m\u001b[33m\"\u001b[39m], post_df[\u001b[33m\"\u001b[39m\u001b[33mLongitude_dir\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mzip\u001b[39m(*post_df[\u001b[33m\"\u001b[39m\u001b[33mLongitude\u001b[39m\u001b[33m\"\u001b[39m].apply(clean_latlon))\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# 3. Define haversine\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\series.py:4935\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4801\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4802\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4807\u001b[39m     **kwargs,\n\u001b[32m   4808\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4809\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4810\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4811\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4926\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4927\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4928\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4929\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4930\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4932\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4933\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4935\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mclean_latlon\u001b[39m\u001b[34m(val)\u001b[39m\n\u001b[32m     23\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m num, val[-\u001b[32m1\u001b[39m]\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '31.4398200-'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Clean coordinate strings\n",
    "# -----------------------------\n",
    "def clean_latlon(val):\n",
    "    \"\"\"\n",
    "    Convert a string like '21.9161 N' to float,\n",
    "    flipping sign if S or W.\n",
    "    \"\"\"\n",
    "    if pd.isna(val):\n",
    "        return np.nan, None   # return None for direction\n",
    "\n",
    "    val = str(val).strip()\n",
    "\n",
    "    # Check last character\n",
    "    if val[-1] in \"NSEW\":\n",
    "        num = float(val[:-1].strip())\n",
    "        if val[-1] in [\"S\", \"W\"]:\n",
    "            return -num, val[-1]\n",
    "        else:\n",
    "            return num, val[-1]\n",
    "    else:\n",
    "        return float(val), None\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Apply cleaning to post_df\n",
    "# -----------------------------\n",
    "\n",
    "# Your original post_df:\n",
    "# e.g. columns: [\"OfficeName\", \"Latitude\", \"Longitude\", ...]\n",
    "\n",
    "# Create clean numeric lat/lon and store direction letters\n",
    "post_df[\"Latitude_clean\"], post_df[\"Latitude_dir\"] = zip(*post_df[\"Latitude\"].apply(clean_latlon))\n",
    "post_df[\"Longitude_clean\"], post_df[\"Longitude_dir\"] = zip(*post_df[\"Longitude\"].apply(clean_latlon))\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Define haversine\n",
    "# -----------------------------\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate distance in km between two lat/lon points.\n",
    "    \"\"\"\n",
    "    R = 6371\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Compute distance from each customer to nearest hub\n",
    "# -----------------------------\n",
    "\n",
    "distances = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    if pd.notnull(row[\"customer_latitude\"]) and pd.notnull(row[\"customer_longitude\"]):\n",
    "        lat = float(row[\"customer_latitude\"])\n",
    "        lon = float(row[\"customer_longitude\"])\n",
    "\n",
    "        # Compute distance to all hubs\n",
    "        post_df[\"dist\"] = post_df.apply(\n",
    "            lambda hub: haversine(\n",
    "                lat,\n",
    "                lon,\n",
    "                hub[\"Latitude_clean\"],\n",
    "                hub[\"Longitude_clean\"]\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "        min_distance = post_df[\"dist\"].min()\n",
    "    else:\n",
    "        min_distance = np.nan\n",
    "\n",
    "    distances.append(min_distance)\n",
    "\n",
    "df[\"distance_to_nearest_hub\"] = distances\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Show results\n",
    "# -----------------------------\n",
    "print(\"✅ Added distance feature.\")\n",
    "print(df.head())\n",
    "\n",
    "# -----------------------------\n",
    "# Optional - show N/S/E/W\n",
    "# -----------------------------\n",
    "# For debugging:\n",
    "print(post_df[[\"OfficeName\", \"Latitude\", \"Latitude_dir\", \"Longitude\", \"Longitude_dir\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d130832c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77773be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec175b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3956143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6262cda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1885e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b76571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353b746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37672329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
